{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (6.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (0.25.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (4.45.0)\n",
      "Requirement already satisfied: update-checker>=0.16 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from praw) (0.16)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from praw) (0.57.0)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.0.1 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from praw) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from update-checker>=0.16->praw) (2.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.13.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->praw) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->praw) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->praw) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\azfar\\anaconda3\\envs\\atneva2\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->praw) (1.25.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw  #Reddit API for fetching data\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm  #for progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating an object by signing in to the app that we've created\n",
    "\n",
    "reddit=praw.Reddit(\n",
    "                   client_id='wzbeY1mKdm2ynw',\n",
    "                   client_secret='4qoywWZTD13cIUiygWuxA1o6fUs',\n",
    "                   user_agent='data_scrape',\n",
    "                   username='azf99',\n",
    "                   password='Reddit_Scrape'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flairs we are searching for=  12\n"
     ]
    }
   ],
   "source": [
    "# Selecting the Subreddit as \"india\"\n",
    "subreddit = reddit.subreddit('india')\n",
    "\n",
    "# Dictionary for storing the datapoints\n",
    "topics = {\"flair\":[],\n",
    "          \"title\":[],\n",
    "          \"score\":[],\n",
    "          \"id\":[],\n",
    "          \"url\":[],\n",
    "          \"comms_num\": [],\n",
    "          \"created\": [],\n",
    "          \"body\":[],\n",
    "          \"author\":[],\n",
    "          \"comments\": []\n",
    "         }\n",
    "\n",
    "# Flairs that we are going to search posts related to\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\",\n",
    "          \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\",\n",
    "          \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n",
    "\n",
    "print(\"Number of flairs we are searching for= \", len(flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 12/12 [1:40:16<00:00, 501.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# Looping over all the flair and fetching different datapoints for posts regarding each flair\n",
    "\n",
    "for flair in tqdm(flairs):\n",
    "  \n",
    "  get_subreddits = subreddit.search(f\"flair_name:{flair}\", limit = 1000)\n",
    "  \n",
    "  for submission in get_subreddits:\n",
    "    \n",
    "    topics[\"flair\"].append(flair)\n",
    "    topics[\"title\"].append(submission.title)\n",
    "    topics[\"score\"].append(submission.score)\n",
    "    topics[\"id\"].append(submission.id)\n",
    "    topics[\"url\"].append(submission.url)\n",
    "    topics[\"comms_num\"].append(submission.num_comments)\n",
    "    topics[\"created\"].append(submission.created)\n",
    "    topics[\"body\"].append(submission.selftext)\n",
    "    topics[\"author\"].append(submission.author)\n",
    "    \n",
    "    comments =  ''\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    # limiting the total comments to 20\n",
    "    max_comment = 20\n",
    "    i = 0\n",
    "    for comment in submission.comments.list():\n",
    "        comments = comment.body + \" \"\n",
    "        i = i+1\n",
    "        if(i > max_comment):\n",
    "            break\n",
    "    topics[\"comments\"].append(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>1044</td>\n",
       "      <td>g014wc</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>130</td>\n",
       "      <td>1.586742e+09</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "      <td>sanand_satwik</td>\n",
       "      <td>wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>1046</td>\n",
       "      <td>g014wc</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>130</td>\n",
       "      <td>1.586742e+09</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "      <td>sanand_satwik</td>\n",
       "      <td>you can check the subreddit r/forhire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "      <td>651</td>\n",
       "      <td>fxofyu</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxofyu...</td>\n",
       "      <td>205</td>\n",
       "      <td>1.586448e+09</td>\n",
       "      <td>We have floods, terrorist attacks, famines due...</td>\n",
       "      <td>TWO-WHEELER-MAFIA</td>\n",
       "      <td>Guys, I know it's sometimes easy to forget thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "      <td>758</td>\n",
       "      <td>g0zlly</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0zlly...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.586871e+09</td>\n",
       "      <td>Hi folks, I really appreciate the warm respons...</td>\n",
       "      <td>sanand_satwik</td>\n",
       "      <td>\\+1\\n\\nAll my prayers for your mother. Hope sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "      <td>263</td>\n",
       "      <td>fvy95j</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>209</td>\n",
       "      <td>1.586207e+09</td>\n",
       "      <td>The corona virus has given me some time to thi...</td>\n",
       "      <td>indianoogler</td>\n",
       "      <td>**“In my own bed, at the age of 80, with a be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flair                                              title  score      id  \\\n",
       "0  AskIndia  Lost my Job, Sick Mother and Paralysed Dad, In...   1044  g014wc   \n",
       "1  AskIndia  Lost my Job, Sick Mother and Paralysed Dad, In...   1046  g014wc   \n",
       "2  AskIndia  Why does the government come with a begging bo...    651  fxofyu   \n",
       "3  AskIndia  Mother's condition is going worse due to hepat...    758  g0zlly   \n",
       "4  AskIndia  Men who are 30+ and have decided not to get ma...    263  fvy95j   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0  https://www.reddit.com/r/india/comments/g014wc...        130  1.586742e+09   \n",
       "1  https://www.reddit.com/r/india/comments/g014wc...        130  1.586742e+09   \n",
       "2  https://www.reddit.com/r/india/comments/fxofyu...        205  1.586448e+09   \n",
       "3  https://www.reddit.com/r/india/comments/g0zlly...         94  1.586871e+09   \n",
       "4  https://www.reddit.com/r/india/comments/fvy95j...        209  1.586207e+09   \n",
       "\n",
       "                                                body             author  \\\n",
       "0  Hi....It's really tough time for everyone. I r...      sanand_satwik   \n",
       "1  Hi....It's really tough time for everyone. I r...      sanand_satwik   \n",
       "2  We have floods, terrorist attacks, famines due...  TWO-WHEELER-MAFIA   \n",
       "3  Hi folks, I really appreciate the warm respons...      sanand_satwik   \n",
       "4  The corona virus has given me some time to thi...       indianoogler   \n",
       "\n",
       "                                            comments  \n",
       "0                                              wrong  \n",
       "1             you can check the subreddit r/forhire   \n",
       "2  Guys, I know it's sometimes easy to forget thi...  \n",
       "3  \\+1\\n\\nAll my prayers for your mother. Hope sh...  \n",
       "4   **“In my own bed, at the age of 80, with a be...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe for all the values\n",
    "topics_data = pd.DataFrame(topics)\n",
    "\n",
    "# Observing the head of the data\n",
    "topics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flair        0\n",
       "title        0\n",
       "score        0\n",
       "id           0\n",
       "url          0\n",
       "comms_num    0\n",
       "created      0\n",
       "body         0\n",
       "author       0\n",
       "comments     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello folks. I'm looking for the best paid vpn option to bypass the blocks Indian operators have placed on us. However, I'm also interested in using the service to access Netflix and Prime's global catalogues (because hotstar streaming quality is shit). I'll also be using other global streaming sites like Crunchyroll, Hulu and a few more, so bandwidth is the most important factor for me. I've got 100mbps downstream with 3.3TB cap per month, so I'm looking for a service that can get me at least 30-50mbps consistently from US servers. If you're using any, please let me know what works best.\\n\\n\\nRegarding free services, they usually come with ads and bandwidth restrictions, so, not planning to use them.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data[\"body\"][160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of posts aquired= 2882\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of posts aquired=\", topics_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs(\"data\")\n",
    "topics_data.to_csv(\"data/data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
